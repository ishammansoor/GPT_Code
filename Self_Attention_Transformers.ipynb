{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrusFDJ1qyTVXx7RP7mM8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishammansoor/GPT_Code/blob/main/Self_Attention_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UbTD24HlJzxF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "# L = the size of the input sequence\n",
        "\n",
        "L, d_k, d_v = 4, 8, 8\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"q: \", q)\n",
        "print(\"k: \", k)\n",
        "print(\"v: \", v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftCBVQT4J6Yk",
        "outputId": "3f4ba238-b851-48b4-cd7f-e3c0538a9618"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q:  [[ 1.18462419  1.71758272  0.30611785  0.29770678  0.02982607 -1.01316031\n",
            "   0.09972832  0.71381426]\n",
            " [ 0.20305684  0.67294698  0.74518149  0.00385025  0.84204858 -0.09611828\n",
            "   0.24116615  2.24492789]\n",
            " [-1.08131676  0.50745548 -1.1076831  -0.81451905  0.60821448 -2.63104095\n",
            "  -0.09473142  0.46363733]\n",
            " [ 0.48983117 -1.49738923 -0.9149111   1.32269724 -0.33860081 -0.48114265\n",
            "  -0.68322736 -2.83297443]]\n",
            "k:  [[-0.41116239  1.23673511  1.82525303 -0.0743678  -0.70796471 -1.33160761\n",
            "   0.81795132  0.70458952]\n",
            " [-0.23586027 -0.60761581  0.80330802 -0.7810145   0.53430326 -0.09057807\n",
            "   0.35906457 -0.31456844]\n",
            " [ 2.40246523  1.44270587  0.48139606 -1.85387129  0.25706481 -0.08579798\n",
            "   0.64726034 -0.16865336]\n",
            " [-0.78922179  1.8772332   0.50778735  1.66574773 -0.6577302   0.9845162\n",
            "  -1.2754653   0.06326837]]\n",
            "v:  [[ 0.44491195  0.07752544 -1.24250232  0.14289091  0.20318407  0.13991395\n",
            "   0.09902659  0.60553795]\n",
            " [-0.75124429  0.74746088  0.99790688  0.83320647  1.16767153  0.34659134\n",
            "   1.97199753  1.40298747]\n",
            " [-0.46108149  0.18378079 -1.29567237  0.5711851   0.48323778 -1.06482544\n",
            "   0.16108124  2.01602184]\n",
            " [ 0.52056593  1.66905021 -0.14891784 -0.27264979 -0.2153533  -0.1275017\n",
            "  -1.85947439  0.78017472]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l_F7dwiK60y",
        "outputId": "098c8074-3ea1-4c3c-e6dd-ef7cf2805fce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.08625981, -1.39067085,  4.95819635,  1.84159085],\n",
              "       [ 3.41949226, -0.02215683,  1.81248158,  0.67379192],\n",
              "       [ 2.43306495,  0.0764674 , -0.64635904, -2.95342296],\n",
              "       [-5.49610451, -0.46518843, -3.88623151, -1.01762421]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var(), k.var(), np.matmul(q, k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CenJXmyTLRVR",
        "outputId": "72442ecc-d530-4e4c-b480-485e82d44573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1770021658090921, 0.9781453951049961, 7.6834159732854435)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1C5Up1i3Qsg",
        "outputId": "806adc1a-a190-4cdf-8254-87e595278eeb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.1770021658090921, 0.9781453951049961, 0.9604269966606803)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMCBwH5C3nLm",
        "outputId": "6c1ddce2-b85e-4894-b4f3-11961d3faf43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.44471101, -0.49167639,  1.75298713,  0.65110069],\n",
              "       [ 1.20897308, -0.00783362,  0.64080901,  0.23822142],\n",
              "       [ 0.86021836,  0.02703531, -0.22852243, -1.0441927 ],\n",
              "       [-1.94316639, -0.16446895, -1.37399033, -0.35978449]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.tril(np.ones((L, L)))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVWq6MqX3nut",
        "outputId": "13448bd0-9ccc-4523-f4d1-77dc447562a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = -np.infty\n",
        "mask[mask == 1] = 0"
      ],
      "metadata": {
        "id": "zpT8Axku3-gu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhSszVqI4Ve2",
        "outputId": "d92c4b76-2bf6-4ee3-9399-1d4c774e3723"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0., -inf, -inf, -inf],\n",
              "       [  0.,   0., -inf, -inf],\n",
              "       [  0.,   0.,   0., -inf],\n",
              "       [  0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled + mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69YjMsqZ4ZLl",
        "outputId": "b5d6426a-186c-42d2-b2f5-666deb4b70da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.44471101,        -inf,        -inf,        -inf],\n",
              "       [ 1.20897308, -0.00783362,        -inf,        -inf],\n",
              "       [ 0.86021836,  0.02703531, -0.22852243,        -inf],\n",
              "       [-1.94316639, -0.16446895, -1.37399033, -0.35978449]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  d_k = q.shape[-1]\n",
        "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled + mask\n",
        "  attention = softmax(scaled)\n",
        "  out = np.matmul(attention, v)\n",
        "  return out, attention"
      ],
      "metadata": {
        "id": "xTMKrh5N4ccW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = softmax(scaled + mask)"
      ],
      "metadata": {
        "id": "bxbvEyFA4uc2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KanRDFEb4xcW",
        "outputId": "f7c44765-6ba8-4598-c5a0-be03eeb0e179"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.        , 0.        ],\n",
              "       [0.7715011 , 0.2284989 , 0.        , 0.        ],\n",
              "       [0.56455594, 0.24539188, 0.19005218, 0.        ],\n",
              "       [0.07374441, 0.4367245 , 0.1302924 , 0.35923869]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_v = np.matmul(attention, v)\n",
        "new_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_GrMEX14ywe",
        "outputId": "5b68786a-818b-4949-f5b5-9b1c3678e0f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.44491195,  0.07752544, -1.24250232,  0.14289091,  0.20318407,\n",
              "         0.13991395,  0.09902659,  0.60553795],\n",
              "       [ 0.17159157,  0.23060495, -0.73057128,  0.30062726,  0.42356839,\n",
              "         0.1871395 ,  0.52699839,  0.78775429],\n",
              "       [-0.0208011 ,  0.26211622, -0.70282919,  0.39368699,  0.49308628,\n",
              "        -0.03833245,  0.57043206,  1.06929113],\n",
              "       [-0.16834502,  0.95568419,  0.12186948,  0.35089382,  0.51053344,\n",
              "        -0.02285941,  0.22151483,  1.20031532]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAgG0e3E5L8W",
        "outputId": "009257ff-67f5-4ad5-8b14-c19479069182"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.44491195,  0.07752544, -1.24250232,  0.14289091,  0.20318407,\n",
              "         0.13991395,  0.09902659,  0.60553795],\n",
              "       [-0.75124429,  0.74746088,  0.99790688,  0.83320647,  1.16767153,\n",
              "         0.34659134,  1.97199753,  1.40298747],\n",
              "       [-0.46108149,  0.18378079, -1.29567237,  0.5711851 ,  0.48323778,\n",
              "        -1.06482544,  0.16108124,  2.01602184],\n",
              "       [ 0.52056593,  1.66905021, -0.14891784, -0.27264979, -0.2153533 ,\n",
              "        -0.1275017 , -1.85947439,  0.78017472]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  d_k = q.shape[-1]\n",
        "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "  if mask is not None:\n",
        "    scaled = scaled + mask\n",
        "  attention = softmax(scaled)\n",
        "  out = np.matmul(attention, v)\n",
        "  return out, attention"
      ],
      "metadata": {
        "id": "QzkFH5JU5QvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}